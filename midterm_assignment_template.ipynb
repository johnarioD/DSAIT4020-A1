{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-edb192a51f1f59eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# TI3145TU Midterm Assignment \n",
    "## Football Players Wages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4b9196b1578a999",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We hope you enjoy this assignment, good luck!\n",
    "\n",
    "Student names: XXX\n",
    "\n",
    "Student numbers: XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b099224fae6a999",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27453141f8aa1fdd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>nationality_name</th>\n",
       "      <th>overall</th>\n",
       "      <th>potential</th>\n",
       "      <th>attacking_crossing</th>\n",
       "      <th>attacking_finishing</th>\n",
       "      <th>attacking_heading_accuracy</th>\n",
       "      <th>attacking_short_passing</th>\n",
       "      <th>...</th>\n",
       "      <th>movement_reactions</th>\n",
       "      <th>movement_balance</th>\n",
       "      <th>defending_standing_tackle</th>\n",
       "      <th>defending_sliding_tackle</th>\n",
       "      <th>goalkeeping_diving</th>\n",
       "      <th>goalkeeping_handling</th>\n",
       "      <th>goalkeeping_kicking</th>\n",
       "      <th>goalkeeping_positioning</th>\n",
       "      <th>goalkeeping_reflexes</th>\n",
       "      <th>log_wages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>b'Korea Republic'</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>b'France'</td>\n",
       "      <td>61.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>b'Korea Republic'</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>b'Paraguay'</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>b'Austria'</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.477121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  height_cm  weight_kg   nationality_name  overall  potential  \\\n",
       "0  27.0      183.0       76.0  b'Korea Republic'     57.0       58.0   \n",
       "1  21.0      182.0       70.0          b'France'     61.0       72.0   \n",
       "2  35.0      182.0       75.0  b'Korea Republic'     68.0       68.0   \n",
       "3  29.0      169.0       70.0        b'Paraguay'     67.0       67.0   \n",
       "4  30.0      176.0       74.0         b'Austria'     65.0       65.0   \n",
       "\n",
       "   attacking_crossing  attacking_finishing  attacking_heading_accuracy  \\\n",
       "0                54.0                 30.0                        55.0   \n",
       "1                58.0                 63.0                        46.0   \n",
       "2                62.0                 68.0                        68.0   \n",
       "3                62.0                 55.0                        50.0   \n",
       "4                63.0                 49.0                        53.0   \n",
       "\n",
       "   attacking_short_passing  ...  movement_reactions  movement_balance  \\\n",
       "0                     53.0  ...                60.0              67.0   \n",
       "1                     62.0  ...                47.0              65.0   \n",
       "2                     70.0  ...                61.0              69.0   \n",
       "3                     71.0  ...                59.0              84.0   \n",
       "4                     63.0  ...                58.0              75.0   \n",
       "\n",
       "   defending_standing_tackle  defending_sliding_tackle  goalkeeping_diving  \\\n",
       "0                       63.0                      58.0                 9.0   \n",
       "1                       31.0                      33.0                 9.0   \n",
       "2                       36.0                      40.0                 8.0   \n",
       "3                       40.0                      55.0                 6.0   \n",
       "4                       65.0                      64.0                12.0   \n",
       "\n",
       "   goalkeeping_handling  goalkeeping_kicking  goalkeeping_positioning  \\\n",
       "0                  13.0                  8.0                     11.0   \n",
       "1                  11.0                  9.0                     12.0   \n",
       "2                  12.0                  7.0                     12.0   \n",
       "3                  10.0                 11.0                     15.0   \n",
       "4                  15.0                 10.0                      8.0   \n",
       "\n",
       "   goalkeeping_reflexes  log_wages  \n",
       "0                  10.0   3.000000  \n",
       "1                  11.0   3.000000  \n",
       "2                   6.0   3.301030  \n",
       "3                   9.0   2.698970  \n",
       "4                  10.0   3.477121  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are your training samples along with their labels\n",
    "data = pd.read_csv('football_wages.csv')\n",
    "data.head()\n",
    "\n",
    "# You need to extract the features and the regression target. The regression target is 'log_wages'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have no null values so we will not attempt imputing or dropping any values\n",
      "\n",
      "If our regressor simply assigned the mean of our data to samples our MAE would be:\n",
      "Mean Absolute Error: 0.4914298670113959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def KNReg():\n",
    "    return KNeighborsRegressor()\n",
    "def SGDReg():\n",
    "    return SGDRegressor( random_state=random_state_seed )\n",
    "def MAE( pred, true ):\n",
    "    return np.mean( np.abs( pred - true ) )\n",
    "\n",
    "random_state_seed = 42\n",
    "\n",
    "number_of_nas = data.isnull().sum().sum()\n",
    "assert number_of_nas == 0\n",
    "print(\"We have no null values so we will not attempt imputing or dropping any values\\n\")\n",
    "\n",
    "X = data.drop(columns=['log_wages'])\n",
    "y = data['log_wages']\n",
    "\n",
    "#print(f\"X: {X.shape}\")\n",
    "#print(f\"y: {y.shape}\")\n",
    "\n",
    "baseline_MAE_train = MAE( y, y.mean() )\n",
    "\n",
    "print( f\"If our regressor simply assigned the mean of our data to samples our MAE would be:\" )\n",
    "print( f\"Mean Absolute Error: {baseline_MAE_train}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_pipeline( data, model ):\n",
    "    one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    \n",
    "    # Define the sets of categorical and numerical columns\n",
    "    categorical_columns = data.select_dtypes(include=[\"object\", \"category\"])\n",
    "\n",
    "    # for categorical values use one hot encoding\n",
    "    # handle_unknown => if the encoder sees a new category during transformation, leave 0 for all values for that item\n",
    "\n",
    "    def test_print(X):\n",
    "        print(X.shape)\n",
    "        return X\n",
    "    print_transformer = FunctionTransformer( test_print )\n",
    "    \n",
    "    preprocess = ColumnTransformer([\n",
    "            (\"cat_pipeline\", one_hot_encoder, categorical_columns.columns)\n",
    "        ],\n",
    "        remainder=\"passthrough\")\n",
    "\n",
    "    return Pipeline([(\"preprocess\", preprocess), (\"model\", model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_pipeline( data, model ):\n",
    "    one_hot_encoder = OneHotEncoder( handle_unknown=\"ignore\", sparse_output=False )\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA( svd_solver=\"full\", n_components=0.99, random_state=random_state_seed )\n",
    "    \n",
    "    def bmi( df ):\n",
    "        df[\"bmi\"] = df[\"weight_kg\"]/((df[\"height_cm\"]/100)**2 )\n",
    "        df = df.drop(columns=[\"weight_kg\",\"height_cm\"])\n",
    "        return df\n",
    "    bmi_transformer = FunctionTransformer( bmi )\n",
    "\n",
    "    def test_print(X):\n",
    "        print(X.shape)\n",
    "        return X\n",
    "    print_transformer = FunctionTransformer( test_print )\n",
    "    \n",
    "    categorical_columns = data.select_dtypes(include=[\"object\", \"category\"])\n",
    "    numerical_columns = data.select_dtypes(exclude=[\"object\", \"category\"])\n",
    "    \n",
    "    preprocessor = ColumnTransformer( transformers = [\n",
    "            ( \"categorical\", one_hot_encoder, categorical_columns.columns ),\n",
    "            ( \"numerical\", scaler, numerical_columns.columns ),\n",
    "            ( \"bmi\", bmi_transformer, [\"height_cm\",\"weight_kg\"] ),\n",
    "        ],\n",
    "        remainder=\"passthrough\" )\n",
    "    pipeline = Pipeline(steps=[( \"preprocessing\", preprocessor ), ( \"pca\", pca ), ( \"training\", model )])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.06335546e+13 1.82098945e+13 2.06453147e+13 1.91112652e+13\n",
      " 1.97069342e+13]\n",
      "[3.1908485  3.20423786 3.71821292 3.47604225 3.33624825]\n",
      "Our basic pipeline with an SGD regressor has a MAE of:\n",
      "Mean Absolute Error: 19940807053000.832031\n",
      "\n",
      "Our Basic pipeline with an KNeighbors regressor has a MAE of:\n",
      "Mean Absolute Error: 0.239692\n",
      "\n",
      "[2.71164691 3.31211778 3.57370629 3.43777051 3.38800328]\n",
      "[3.02110204 3.0704365  3.50881361 3.4510545  3.54048611]\n",
      "Our extra pipeline with an SGD regressor has a MAE of:\n",
      "Mean Absolute Error: 0.254329\n",
      "\n",
      "Our extra pipeline with an KNeighbors regressor has a MAE of:\n",
      "Mean Absolute Error: 0.228339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model_pipeline( pipeline_fun, model, X, y ):\n",
    "    pipeline = pipeline_fun( X, model )\n",
    "    pipeline.fit( X, y )\n",
    "    y_pred = pipeline.predict( X )\n",
    "    return pipeline, MAE( y_pred, y )\n",
    "\n",
    "def evaluate_pipeline( pipeline, X, y ):\n",
    "    y_pred = pipeline.predict( X )\n",
    "    return MAE( y_pred, y )\n",
    "\n",
    "SGD_pipeline_basic, SGD_MAE_train_basic = train_model_pipeline( pipeline_fun=get_basic_pipeline, model=SGDReg(), X=X, y=y )\n",
    "KN_pipeline_basic, KN_MAE_train_basic = train_model_pipeline( pipeline_fun=get_basic_pipeline, model=KNReg(), X=X, y=y )\n",
    "\n",
    "print( f\"Our basic pipeline with an SGD regressor has a MAE of:\" )\n",
    "print( f\"Mean Absolute Error: {SGD_MAE_train_basic:.6f}\\n\" )\n",
    "\n",
    "print( f\"Our Basic pipeline with an KNeighbors regressor has a MAE of:\" )\n",
    "print( f\"Mean Absolute Error: {KN_MAE_train_basic:.6f}\\n\" )\n",
    "\n",
    "SGD_pipeline, SGD_MAE_train = train_model_pipeline( pipeline_fun=get_preprocessed_pipeline, model=SGDReg(), X=X, y=y )\n",
    "KN_pipeline, KN_MAE_train = train_model_pipeline( pipeline_fun=get_preprocessed_pipeline, model=KNReg(), X=X, y=y )\n",
    "\n",
    "print( f\"Our extra pipeline with an SGD regressor has a MAE of:\" )\n",
    "print( f\"Mean Absolute Error: {SGD_MAE_train:.6f}\\n\" )\n",
    "\n",
    "print( f\"Our extra pipeline with an KNeighbors regressor has a MAE of:\" )\n",
    "print( f\"Mean Absolute Error: {KN_MAE_train:.6f}\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.80680749 3.21131782 3.61200169 3.46055051 3.36104472]\n",
      "MAE:  0.2705652082818827\n",
      "Optimal params:  {'learning_rate': 'adaptive', 'loss': 'huber'}\n"
     ]
    }
   ],
   "source": [
    "def SGD_Gridsearch(X_train, y_train):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    #losses = [ 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive' ]\n",
    "    #penalties = [ 'l2', 'l1', 'elasticnet', None ]\n",
    "    #alphas = [ j*10**(i-10) for i in range(15) for j in range(1,10) ]\n",
    "    #l1_ratios = [ 0.1*i for i in range(11) ] # Only for elasticnet\n",
    "    # Fit intercept not tested for as we do standard scaling to remove the mean\n",
    "    # max_iter left standard, no sense in increasing epochs as the model can only converge more\n",
    "    # tol, much like max_iter this has no effect on model performance. It only stops training when some cut-off is reach which could be destructcive in grid_search\n",
    "    #shuffle = True # Shuffling should only make our model more robust\n",
    "    # verbosity unrelated to model\n",
    "    #epsilons = [ j*10**(i-4) for i in range(5) for j in range(1,10)  ] # Given squared loss and our MAE observations the loss should be in the order of 10^-k for some positive k. Our prediction is that 0<k<4\n",
    "    #random_state = random_state_seed # For reproducability\n",
    "    #learning_rates = [ 'constant', 'optimal', 'invscaling', 'adaptive' ]\n",
    "    #eta0s = [ j*10**(i-6) for i in range(7) for j in range(1,10) ]\n",
    "    # We leave power_t as the default since we do not know what values would be more appropriate and cannot search (-inf,inf) in a reasonable time\n",
    "    # early_stopping = False by default\n",
    "    # validation_fraction is not necessary to be set without early_stopping\n",
    "    # n_iter_no_change again unnecessary without early_stopping\n",
    "    #warm_start=False # While it is false by default we set it again as we definitively do not want this since it would be detrimental to the grid search\n",
    "    # average left false as is by default\n",
    "\n",
    "    params = {\n",
    "        \"loss\": [ 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive' ], # 4\n",
    "        # \"penalty\": [ 'l2', 'l1', 'elasticnet', None ], # 4\n",
    "        # \"alpha\": [ 10**(i-10) for i in range(11) ], # 10\n",
    "        # \"l1_ratio\": [ 0.1*i for i in range(11) ], # 10\n",
    "        # \"epsilon\": [ 10**(i-4) for i in range(6) ], # 5\n",
    "        \"learning_rate\": [ 'constant', 'optimal', 'invscaling', 'adaptive' ], # 4\n",
    "        # \"eta0\": [ 10**(i-6) for i in range(7) ], # 7\n",
    "        # \"shuffle\": [ True ],\n",
    "        # \"random_state\": [ random_state_seed ],\n",
    "        # \"warm_start\": [ False ]\n",
    "    }\n",
    "    model = GridSearchCV( SGDRegressor(), params, cv = 5, scoring='neg_mean_absolute_error' )\n",
    "    _, mean_absolute_error = train_model_pipeline( get_preprocessed_pipeline, model, X_train, y_train )\n",
    "    return mean_absolute_error, model\n",
    "\n",
    "GS_SGD_MAE, model = SGD_Gridsearch(X, y)\n",
    "# mae_test_sgd = evaluate_pipeline( pipeline=model.best_estimator_, X=X_test, y=y_test )\n",
    "print(\"MAE: \", GS_SGD_MAE)\n",
    "print(\"Optimal params: \", model.best_params_)     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.08538189 3.12275083 3.5680341  3.41031146 3.47357253]\n",
      "MAE:  0.2570476752811195\n",
      "Optimal params:  {'n_neighbors': 18, 'p': 2}\n",
      "Best score:  -0.27274460759437985\n"
     ]
    }
   ],
   "source": [
    "def KN_Gridsearch(X_train, y_train):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # n_neighbors: number of neighbors to consider\n",
    "    # p: power parameter for the Minkowski metric\n",
    "\n",
    "    params = {\n",
    "        \"n_neighbors\": [i for i in range(1, 30)],\n",
    "        # Weights \n",
    "        # Algortihm \n",
    "        # Leaf size \n",
    "        \"p\": [1,2]\n",
    "    }\n",
    "    model = GridSearchCV( KNeighborsRegressor(), params, cv = 5, scoring='neg_mean_absolute_error' )\n",
    "\n",
    "    _, mean_absolute_error = train_model_pipeline( get_preprocessed_pipeline, model, X_train, y_train )\n",
    "    return mean_absolute_error, model\n",
    "\n",
    "mean_absolute_error_kn, model = KN_Gridsearch(X, y)\n",
    "print(\"MAE: \", mean_absolute_error_kn)\n",
    "print(\"Optimal params: \", model.best_params_) \n",
    "print(\"Best score: \", model.best_score_)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the autograder you will need to provide two things: 1) estimate of the MAE of your model on unseen data, 2) the predictions on the autograder data. For the autograder data we only provide the features and not the regression targets. Thus, you cannot compute the MAE on this data yourself - you need to estimate that with the data provided above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14178, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_autograder = pd.read_csv('football_autograde.csv')\n",
    "data_autograder.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Replace this with your own estimate of the MAE of your best model\n",
    "estimate_MAE_on_new_data = np.array([SGD_MAE_train])\n",
    "\n",
    "# TODO Replace this with the predictions of your best model\n",
    "# via e.g. prediction = model.predict(data_autograder)\n",
    "# your predictions here should again be the $log_{10}(wage)$ of the football player, just as in the provided data. \n",
    "predictions_autograder_data = SGD_pipeline.predict( data_autograder )\n",
    "\n",
    "# Upload this file to the Vocareum autograder:\n",
    "result = np.append(estimate_MAE_on_new_data, predictions_autograder_data)\n",
    "pd.DataFrame(result).to_csv(\"autograder_submission.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
